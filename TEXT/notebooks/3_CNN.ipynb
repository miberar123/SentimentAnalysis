{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Convolutional Neural Network (CNN)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Custom libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from functions.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment\n",
      "0  everyone think he laugh screwing people instea...\n",
      "1                                               fuck\n",
      "2                               make feel threatened\n",
      "3                              dirty southern wanker\n",
      "4  omg good enough help u playoff dumbass bronco ...\n",
      "   label\n",
      "0     27\n",
      "1      2\n",
      "2     14\n",
      "3      3\n",
      "4     26\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('../data/X_train.tsv', sep='\\t')\n",
    "X_test = pd.read_csv('../data/X_test.tsv', sep='\\t')\n",
    "X_val = pd.read_csv('../data/X_val.tsv', sep='\\t')\n",
    "\n",
    "y_train = pd.read_csv('../data/y_train.tsv', sep='\\t')\n",
    "y_test = pd.read_csv('../data/y_test.tsv', sep='\\t')\n",
    "y_val = pd.read_csv('../data/y_val.tsv', sep='\\t')\n",
    "\n",
    "# Check\n",
    "print(X_train.head())\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, Padding and Sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "# Obtain padded train and test sequences, length of longest sequence and vocabulary size\n",
    "train_padded, val_padded, max_seq_len, vocab_size, tokenizer = tokenization(tokenizer, X_train, X_val, \"comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de emociones\n",
    "cat_labels = [\n",
    "    'admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion',\n",
    "    'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment',\n",
    "    'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism',\n",
    "    'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'\n",
    "]\n",
    "num_labels = len(cat_labels)\n",
    "\n",
    "# Convertir las etiquetas a un formato adecuado para el entrenamiento\n",
    "y_train_categorical = to_categorical(y_train, num_classes=num_labels)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=50, input_length=max_seq_len))\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv1D(filters=16, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Flatten and classifier\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_labels, activation=\"softmax\"))  # Usar softmax para clasificación múltiple\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "624/624 [==============================] - ETA: 0s - loss: 2.9729 - accuracy: 0.1528\n",
      "Epoch 1: val_loss improved from inf to 2.71873, saving model to ../trained_models\\cnn.h5\n",
      "624/624 [==============================] - 5s 6ms/step - loss: 2.9729 - accuracy: 0.1528 - val_loss: 2.7187 - val_accuracy: 0.2601\n",
      "Epoch 2/30\n",
      "620/624 [============================>.] - ETA: 0s - loss: 2.7341 - accuracy: 0.2308\n",
      "Epoch 2: val_loss improved from 2.71873 to 2.58660, saving model to ../trained_models\\cnn.h5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.7340 - accuracy: 0.2308 - val_loss: 2.5866 - val_accuracy: 0.2664\n",
      "Epoch 3/30\n",
      "618/624 [============================>.] - ETA: 0s - loss: 2.6326 - accuracy: 0.2556\n",
      "Epoch 3: val_loss improved from 2.58660 to 2.54288, saving model to ../trained_models\\cnn.h5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.6332 - accuracy: 0.2555 - val_loss: 2.5429 - val_accuracy: 0.2815\n",
      "Epoch 4/30\n",
      "618/624 [============================>.] - ETA: 0s - loss: 2.5763 - accuracy: 0.2702\n",
      "Epoch 4: val_loss improved from 2.54288 to 2.50418, saving model to ../trained_models\\cnn.h5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.5765 - accuracy: 0.2701 - val_loss: 2.5042 - val_accuracy: 0.2879\n",
      "Epoch 5/30\n",
      "614/624 [============================>.] - ETA: 0s - loss: 2.5284 - accuracy: 0.2819\n",
      "Epoch 5: val_loss improved from 2.50418 to 2.47828, saving model to ../trained_models\\cnn.h5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.5269 - accuracy: 0.2826 - val_loss: 2.4783 - val_accuracy: 0.2877\n",
      "Epoch 6/30\n",
      "619/624 [============================>.] - ETA: 0s - loss: 2.4926 - accuracy: 0.2924\n",
      "Epoch 6: val_loss did not improve from 2.47828\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.4927 - accuracy: 0.2924 - val_loss: 2.4799 - val_accuracy: 0.2721\n",
      "Epoch 7/30\n",
      "623/624 [============================>.] - ETA: 0s - loss: 2.4620 - accuracy: 0.2995\n",
      "Epoch 7: val_loss improved from 2.47828 to 2.45229, saving model to ../trained_models\\cnn.h5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.4614 - accuracy: 0.2998 - val_loss: 2.4523 - val_accuracy: 0.2997\n",
      "Epoch 8/30\n",
      "616/624 [============================>.] - ETA: 0s - loss: 2.4356 - accuracy: 0.3056\n",
      "Epoch 8: val_loss did not improve from 2.45229\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.4361 - accuracy: 0.3054 - val_loss: 2.4668 - val_accuracy: 0.2766\n",
      "Epoch 9/30\n",
      "624/624 [==============================] - ETA: 0s - loss: 2.4181 - accuracy: 0.3067\n",
      "Epoch 9: val_loss did not improve from 2.45229\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.4181 - accuracy: 0.3067 - val_loss: 2.4656 - val_accuracy: 0.2948\n",
      "Epoch 10/30\n",
      "624/624 [==============================] - ETA: 0s - loss: 2.4004 - accuracy: 0.3115\n",
      "Epoch 10: val_loss did not improve from 2.45229\n",
      "624/624 [==============================] - 4s 7ms/step - loss: 2.4004 - accuracy: 0.3115 - val_loss: 2.4550 - val_accuracy: 0.2789\n",
      "Epoch 11/30\n",
      "621/624 [============================>.] - ETA: 0s - loss: 2.3851 - accuracy: 0.3147\n",
      "Epoch 11: val_loss did not improve from 2.45229\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.3852 - accuracy: 0.3146 - val_loss: 2.4629 - val_accuracy: 0.2783\n",
      "Epoch 12/30\n",
      "620/624 [============================>.] - ETA: 0s - loss: 2.3758 - accuracy: 0.3161Restoring model weights from the end of the best epoch: 7.\n",
      "\n",
      "Epoch 12: val_loss did not improve from 2.45229\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 2.3747 - accuracy: 0.3166 - val_loss: 2.4633 - val_accuracy: 0.2830\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Definir EarlyStopping y ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "mc = ModelCheckpoint(filepath='../trained_models/cnn.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_padded, y_train_categorical,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    validation_data=(val_padded, y_val_categorical),\n",
    "    callbacks=[es, mc]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADNEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
